{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time as tm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "决策树\n",
    "'''\n",
    "class decision_tree_regressor:\n",
    "\n",
    "    def __init__(self, max_fec_num, max_depth):\n",
    "        self.max_fec_num = max_fec_num\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    '''\n",
    "    计算方差\n",
    "    '''\n",
    "    def cal_variance(self, label):\n",
    "        return (np.var(label) * label.shape[0]).item()\n",
    "\n",
    "    '''\n",
    "    计算平均数\n",
    "    '''\n",
    "    def cal_mean(self, label):\n",
    "        return np.mean(label)\n",
    "    \n",
    "    '''\n",
    "    划分数据集\n",
    "    '''\n",
    "    def split_dataset(self, data, label, index, value):\n",
    "        l = np.nonzero(data.iloc[:, index] < value)[0]\n",
    "        r = np.nonzero(data.iloc[:, index] > value)[0]\n",
    "        return data.iloc[l,:], label.iloc[l,:], data.iloc[r,:], label.iloc[r,:]\n",
    "\n",
    "    '''\n",
    "    选取指定的最大个特征，在这些个特征中，选取分割时的最优特征\n",
    "    '''\n",
    "    def select_best_fec(self, data, label):\n",
    "        fec_num = data.shape[1]\n",
    "        best_fec_index, best_fec_value = 0, 0\n",
    "        fec_index = [np.random.randint(fec_num) for i in range(self.max_fec_num)]\n",
    "        bestS = float('inf')\n",
    "        S = self.cal_variance(label)\n",
    "        for index in fec_index:\n",
    "            for value in set(data.iloc[:, index]):\n",
    "                l_x, l_y, r_x, r_y = self.split_dataset(data, label, index, value)\n",
    "                newS = self.cal_variance(l_y) + self.cal_variance(r_y)\n",
    "                if newS < bestS:\n",
    "                    bestS = newS\n",
    "                    best_fec_index = index\n",
    "                    best_fec_value = value\n",
    "        if S - bestS < 0.0000001:\n",
    "            return None, self.cal_mean(label)\n",
    "        return best_fec_index, best_fec_value\n",
    "\n",
    "    def build(self, data, label):\n",
    "        self.tree = self.__build_tree(data, label, 0)\n",
    "        return self.tree\n",
    "\n",
    "    def __build_tree(self, data, label, depth):\n",
    "        print(depth)\n",
    "        best_fec_index, best_fec_value = self.select_best_fec(data, label)\n",
    "        if best_fec_index == None:\n",
    "            return best_fec_value\n",
    "        tree = {}\n",
    "        if depth >= self.max_depth:\n",
    "            return self.cal_mean(label)\n",
    "        tree[\"best_fec\"] = best_fec_index\n",
    "        tree[\"best_val\"] = best_fec_value\n",
    "        l_x, l_y, r_x, r_y = self.split_dataset(data, label, best_fec_index, best_fec_value)\n",
    "        tree[\"left\"] = self.__build_tree(l_x, l_y, depth+1)\n",
    "        tree[\"right\"] = self.__build_tree(r_x, r_y, depth+1)\n",
    "        return tree\n",
    "\n",
    "    def predict(self, data):\n",
    "        if not isinstance(self.tree, dict):\n",
    "            return None\n",
    "        return [self.__predict(self.tree, d) for d in data]\n",
    "\n",
    "    def __predict(self, tree, x):\n",
    "        if x[tree['best_fec']] > tree['best_val']:\n",
    "            if type(tree['left']) == float:\n",
    "                return tree['left']\n",
    "            return self.__predict(tree['left'], x)\n",
    "        else:\n",
    "            if type(tree['right']) == float:\n",
    "                return tree['right']\n",
    "            return self.__predict(tree['right'], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_forest_regressor:\n",
    "    def __init__(self, n_estimators=10, max_fec_num=10, max_depth=10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_fec_num = max_fec_num\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    '''\n",
    "    基础实现\n",
    "    '''\n",
    "    # 基础实现\n",
    "    def fit(self, data, label):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            dec_tree = decision_tree_regressor(\n",
    "                self.max_fec_num, self.max_depth)\n",
    "            tree = dec_tree.build(data, label)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    # 基础实现\n",
    "    def predict(self, data):\n",
    "        if not isinstance(self.trees, list):\n",
    "            return None\n",
    "        result = np.zeros(data.shape[0], dtype=np.float)\n",
    "        for tree in self.trees:\n",
    "            result += tree.predict(data)\n",
    "        result /= self.n_estimators\n",
    "        return result\n",
    "    \n",
    "    '''\n",
    "    并行化\n",
    "    '''\n",
    "    # 并行训练\n",
    "    def fit_worker(self, data, label, q):\n",
    "        dec_tree = decision_tree_regressor(self.max_fec_num, self.max_depth)\n",
    "        tree = dec_tree.build(data, label)\n",
    "        q.put(tree)\n",
    "\n",
    "    def mul_fit(self, data, label):\n",
    "        if not isinstance(self.trees, list):\n",
    "            return None\n",
    "        q = multiprocessing.Queue()\n",
    "        jobs = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            p = multiprocessing.Process(target=self.fit_worker, args=(data, label, q))\n",
    "            jobs.append(p)\n",
    "        for p in jobs:\n",
    "            p.join()\n",
    "        self.trees = [q.get() for j in jobs]\n",
    "\n",
    "    # 并行预测\n",
    "    def predict_worker(self, tree, data, q):\n",
    "        res = tree.predict(data)\n",
    "        q.put(res)\n",
    "\n",
    "    def mul_predict(self, data):\n",
    "        if not isinstance(self.trees, list):\n",
    "            return None\n",
    "        q = multiprocessing.Queue()\n",
    "        jobs = []\n",
    "        for tree in self.trees:\n",
    "            p = multiprocessing.Process(target=self.predict_worker, args=(tree, data, q))\n",
    "            jobs.append(p)\n",
    "        for p in jobs:\n",
    "            p.join()\n",
    "        result = [q.get() for j in jobs]\n",
    "        return sum(result) / self.n_estimators\n",
    "\n",
    "    '''\n",
    "    进程池并行化\n",
    "    '''\n",
    "    def pool_fit(self, data, label):\n",
    "        if not isinstance(self.trees, list):\n",
    "            return None\n",
    "        pool = multiprocessing.Pool(processes=4)\n",
    "        self.trees = []\n",
    "        jobs = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            p = pool.apply_async(self.fit_worker, (data, label, ))\n",
    "            jobs.append(p)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        self.trees = [j.get() for j in jobs]\n",
    "\n",
    "    def pool_predict(self, data):\n",
    "        if not isinstance(self.trees, list):\n",
    "            return None\n",
    "        pool = multiprocessing.Pool(processes=4)\n",
    "        jobs = []\n",
    "        for tree in self.trees:\n",
    "            p = pool.apply_async(self.predict_worker, (tree, data, ))\n",
    "            jobs.append(p)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        result = [j.get() for j in jobs]\n",
    "        return sum(result) / self.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_1 = pd.read_csv(\"./data/train1.csv\", header=None)\n",
    "data_train_2 = pd.read_csv(\"./data/train2.csv\", header=None)\n",
    "data_train_3 = pd.read_csv(\"./data/train3.csv\", header=None)\n",
    "data_train_4 = pd.read_csv(\"./data/train4.csv\", header=None)\n",
    "data_train_5 = pd.read_csv(\"./data/train5.csv\", header=None)\n",
    "\n",
    "data_test_1 = pd.read_csv(\"./data/test1.csv\", header=None)\n",
    "data_test_2 = pd.read_csv(\"./data/test2.csv\", header=None)\n",
    "data_test_3 = pd.read_csv(\"./data/test3.csv\", header=None)\n",
    "data_test_4 = pd.read_csv(\"./data/test4.csv\", header=None)\n",
    "data_test_5 = pd.read_csv(\"./data/test5.csv\", header=None)\n",
    "data_test_6 = pd.read_csv(\"./data/test6.csv\", header=None)\n",
    "\n",
    "label_1 = pd.read_csv(\"./data/label1.csv\", header=None)\n",
    "label_2 = pd.read_csv(\"./data/label2.csv\", header=None)\n",
    "label_3 = pd.read_csv(\"./data/label3.csv\", header=None)\n",
    "label_4 = pd.read_csv(\"./data/label4.csv\", header=None)\n",
    "label_5 = pd.read_csv(\"./data/label5.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_begin = tm.time()\n",
    "\n",
    "x = pd.concat([data_train_1, data_train_2, data_train_3, data_train_4, data_train_5], ignore_index=True)\n",
    "y = pd.concat([label_1, label_2, label_3, label_4, label_5], ignore_index=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "time_end = tm.time()\n",
    "\n",
    "random_forest = random_forest_regressor(2, 2, 2)\n",
    "random_forest.fit(x_train, y_train)\n",
    "\n",
    "print('total time: ', time_end - time_begin, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest = random_forest_regressor(8, 5, 8)\n",
    "# random_forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = random_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# score = r2_score(y_test, predictions)\n",
    "# print(\"R2 Score: %.2f%%\" % (score * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
